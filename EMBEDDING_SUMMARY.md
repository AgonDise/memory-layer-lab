# Embedding & Data Population Summary

## ğŸ¯ Váº¥n Ä‘á» Ä‘Ã£ giáº£i quyáº¿t

Báº¡n cÃ³ `schema.yaml` nhÆ°ng chÆ°a biáº¿t:
1. âœ… CÃ¡ch táº¡o embeddings giáº£ láº­p
2. âœ… CÃ¡ch Ä‘Æ°a data vÃ o Ä‘á»ƒ test

## ğŸ“¦ Files Ä‘Ã£ táº¡o

### 1. `utils/embedding_utils.py` - Embedding utilities
**Classes:**
- `FakeEmbeddingGenerator` - Táº¡o embeddings giáº£ láº­p (deterministic)
- `RealEmbeddingGenerator` - Táº¡o embeddings tháº­t (sentence-transformers)
- `EmbeddingCache` - Cache embeddings vÃ o disk
- `get_embedder()` - Factory function

**Features:**
```python
# Fake embeddings (khÃ´ng cáº§n model)
embedder = FakeEmbeddingGenerator(embedding_dim=384)
emb = embedder.generate("your text here")

# Same text â†’ same embedding
emb1 = embedder.generate("hello")
emb2 = embedder.generate("hello")
assert emb1 == emb2  # âœ… True

# Calculate similarity
sim = embedder.cosine_similarity(emb1, emb2)
```

### 2. `populate_from_schema.py` - Data population script
**Chá»©c nÄƒng:**
- Load data tá»« `schema.yaml`
- Generate embeddings tá»± Ä‘á»™ng
- Populate vÃ o STM, MTM, LTM
- Demo queries vá»›i káº¿t quáº£

**Usage:**
```bash
python populate_from_schema.py
```

### 3. `POPULATE_DATA_GUIDE.md` - Complete guide
- Giáº£i thÃ­ch embeddings hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o
- Schema format chi tiáº¿t
- Usage instructions
- Troubleshooting
- Examples

### 4. `example_embedding_usage.py` - Quick example
VÃ­ dá»¥ Ä‘Æ¡n giáº£n vá»:
- Generate embeddings
- Add vÃ o memory layers
- Search by embedding
- Calculate similarity

**Usage:**
```bash
python example_embedding_usage.py
```

---

## ğŸš€ Quick Start

### Step 1: CÃ i Ä‘áº·t
```bash
pip install pyyaml numpy
```

### Step 2: Cháº¡y example
```bash
# Quick example
python example_embedding_usage.py

# Full data population
python populate_from_schema.py
```

### Step 3: Customize
Edit `schema.yaml` vá»›i data cá»§a báº¡n:

```yaml
short_term:
  - role: "user"
    content: "Your message here"

mid_term:
  - text: "Your summary here"
    metadata:
      file: "your_file.py"

long_term:
  vector:
    - text: "Your document here"
      metadata:
        source: "documentation"
```

---

## ğŸ§ª Embedding Methods

### Method 1: Fake Embeddings (Recommended for testing)

**Pros:**
- âœ… KhÃ´ng cáº§n model/API
- âœ… Fast & reproducible
- âœ… Deterministic (same text â†’ same embedding)
- âœ… Good for unit tests

**Cons:**
- âŒ KhÃ´ng cÃ³ semantic meaning tháº­t
- âŒ Similarity scores khÃ´ng chÃ­nh xÃ¡c nhÆ° real embeddings

**Usage:**
```python
from utils import FakeEmbeddingGenerator

embedder = FakeEmbeddingGenerator(embedding_dim=384)
emb = embedder.generate("login_user function")
```

### Method 2: Real Embeddings (For production)

**Pros:**
- âœ… True semantic similarity
- âœ… Better search quality
- âœ… Industry standard

**Cons:**
- âŒ Requires sentence-transformers
- âŒ Slower than fake
- âŒ Needs model download

**Usage:**
```python
from utils import RealEmbeddingGenerator

embedder = RealEmbeddingGenerator(model_name='all-MiniLM-L6-v2')
emb = embedder.generate("login_user function")
```

---

## ğŸ“Š Schema Format Reference

### Short-term Memory
```yaml
short_term:
  - id: "msg_001"
    role: "user"              # Required
    content: "Your message"   # Required
    token_count: 12           # Optional
    timestamp: "ISO8601"      # Optional
```

### Mid-term Memory
```yaml
mid_term:
  - id: "conv_001"
    text: "Summary text"      # Required
    embedding: [...]          # Optional (auto-generated)
    metadata:                 # Optional
      file: "file.py"
      function: "func_name"
      commit: "abc123"
      timestamp: "ISO8601"
```

### Long-term Memory - Vector
```yaml
long_term:
  vector:
    - id: "kb_001"
      text: "Document text"   # Required
      embedding: [...]        # Optional (auto-generated)
      metadata:               # Optional
        source: "doc"
        topic: "topic_name"
```

### Long-term Memory - Graph
```yaml
long_term:
  graph:
    nodes:
      - id: "node_id"
        label: "Function"     # Function|Class|Commit|Doc
        name: "func_name"
    edges:
      - from: "node_1"
        to: "node_2"
        type: "CALLS"         # Relationship type
```

---

## ğŸ” Example Queries

### Query Short-term Memory
```python
from utils import FakeEmbeddingGenerator

embedder = FakeEmbeddingGenerator()
query_emb = embedder.generate("login function")

# Search
results = stm.search_by_embedding(query_emb, top_k=5)
for msg in results:
    print(f"[{msg['role']}] {msg['content']}")
    print(f"Score: {msg['relevance_score']:.3f}")
```

### Query Mid-term Memory
```python
results = mtm.search_by_embedding(query_emb, top_k=5)
for chunk in results:
    print(chunk['summary'])
    print(f"Score: {chunk['relevance_score']:.3f}")
```

### Query Long-term Vector DB
```python
results = ltm.vector_db.search(query_emb, top_k=5)
for doc in results:
    print(f"[{doc['id']}] {doc['content']}")
    print(f"Score: {doc['score']:.3f}")
```

---

## ğŸ’¡ Tips & Best Practices

### 1. Embedding Dimension
- **384**: Good balance (default)
- **768**: Better quality, slower
- **128**: Faster, less accurate

### 2. Caching
```python
from utils import EmbeddingCache

cache = EmbeddingCache('my_cache.json')
if not cache.has(text):
    emb = embedder.generate(text)
    cache.put(text, emb)
    cache.save()
else:
    emb = cache.get(text)
```

### 3. Batch Processing
```python
texts = ["text1", "text2", "text3"]
embeddings = embedder.generate_batch(texts)  # Faster
```

### 4. Normalize Vectors
Always normalize for cosine similarity:
```python
emb = emb / np.linalg.norm(emb)
```

---

## ğŸ¬ Complete Workflow

```python
# 1. Setup
from utils import FakeEmbeddingGenerator
from core import ShortTermMemory

embedder = FakeEmbeddingGenerator(384)
stm = ShortTermMemory()

# 2. Add data with embeddings
messages = [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi there"}
]

for msg in messages:
    emb = embedder.generate(msg['content'])
    stm.add(role=msg['role'], content=msg['content'], embedding=emb)

# 3. Query
query_emb = embedder.generate("greeting")
results = stm.search_by_embedding(query_emb, top_k=3)

# 4. Show results
for r in results:
    print(f"{r['content']} (score: {r['relevance_score']:.3f})")
```

---

## ğŸ“š Files Organization

```
memory-layer-lab/
â”œâ”€â”€ schema.yaml                    # Your data schema
â”œâ”€â”€ populate_from_schema.py        # âœ¨ Main script
â”œâ”€â”€ example_embedding_usage.py     # âœ¨ Quick example
â”œâ”€â”€ POPULATE_DATA_GUIDE.md         # âœ¨ Complete guide
â”œâ”€â”€ EMBEDDING_SUMMARY.md           # âœ¨ This file
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ embedding_utils.py         # âœ¨ Embedding utilities
â”‚
â””â”€â”€ core/
    â”œâ”€â”€ short_term.py              # Has search_by_embedding()
    â”œâ”€â”€ mid_term.py                # Has search_by_embedding()
    â””â”€â”€ long_term.py               # Has vector DB integration
```

---

## âœ… Checklist

### Testing
- [ ] Run `python example_embedding_usage.py`
- [ ] Verify embeddings are generated
- [ ] Check search results make sense

### Data Population
- [ ] Edit `schema.yaml` with your data
- [ ] Run `python populate_from_schema.py`
- [ ] Verify all memory layers populated
- [ ] Test queries with your data

### Production
- [ ] Consider switching to real embeddings
- [ ] Enable embedding cache
- [ ] Tune embedding dimension
- [ ] Add more test data

---

## ğŸ”— Related Documentation

- **POPULATE_DATA_GUIDE.md** - Detailed guide
- **WORKFLOW.md** - Overall system workflow
- **NEO4J_SETUP.md** - Neo4j integration
- **README.md** - Project overview

---

## ğŸ†˜ Troubleshooting

### "No embeddings generated"
```python
# Check if embedder is working
embedder = FakeEmbeddingGenerator()
emb = embedder.generate("test")
print(len(emb))  # Should be 384
```

### "Low similarity scores"
- Fake embeddings don't have real semantic meaning
- Try with more similar text
- Consider using real embeddings

### "schema.yaml not found"
```bash
# Ensure in correct directory
pwd  # Should show memory-layer-lab
ls schema.yaml  # Should exist
```

---

## ğŸ‰ Summary

**Báº¡n cÃ³ thá»ƒ:**
1. âœ… Generate embeddings (fake hoáº·c real)
2. âœ… Load data tá»« schema.yaml
3. âœ… Populate vÃ o STM, MTM, LTM
4. âœ… Query vá»›i semantic search
5. âœ… Test vá»›i data cá»§a báº¡n

**Báº¯t Ä‘áº§u ngay:**
```bash
python example_embedding_usage.py
python populate_from_schema.py
```

**Customize:**
- Edit `schema.yaml`
- Adjust embedding dimension
- Switch to real embeddings
- Add more queries

---

**Date**: 2025-09-30  
**Status**: âœ… Complete  
**Ready to use**: âœ… Yes
