# ğŸ§© Workflow Memory Layer Lab (Updated)

## Tá»•ng quan Workflow

```mermaid
flowchart TD
    A[User Query] --> B[Input Preprocessor]
    B --> C[Short-term Memory]
    B --> D[Mid-term Memory]
    B --> E[Long-term Memory]

    D --> D1[Neo4j Temporal Graph]
    D --> D2[Neo4j Knowledge Graph]

    E --> E1[Neo4j Knowledge Graph (long-term)]
    E --> E2[Vector DB (semantic search)]

    C --> F[Memory Aggregator]
    D1 --> F
    D2 --> F
    E1 --> F
    E2 --> F

    F --> G[Context Compressor]
    G --> H[Reasoner / LLM]
    H --> I[Response Synthesizer]
    I --> J[Final Output]
```

---

## ğŸ”¹ CÃ¡c Module & Vai trÃ²

### 1. Input Preprocessor
- **Input**: user query (string, code snippet, command).
- **Nhiá»‡m vá»¥**:
  - Chuáº©n hÃ³a input (lowercase, remove noise).
  - XÃ¡c Ä‘á»‹nh intent (search code, há»i bug, tÃ i liá»‡u, commit log).
  - Táº¡o embedding vector (giáº£ láº­p hoáº·c model tháº­t).
- **Output**: structured query object:
```json
{
  "raw_text": "Find bug in checkpoints.rs",
  "embedding": [0.123, -0.456, ...],
  "intent": "code_search"
}
```

### 2. Short-term Memory (STM)
- **Input**: Query object.
- **Nhiá»‡m vá»¥**: LÆ°u giá»¯ ngá»¯ cáº£nh gáº§n (5â€“20 turn chat gáº§n nháº¥t, code buffer).
- **Output**: small context chunk (tokens < 1k).
```json
{
  "stm_context": "last 10 user queries and responses"
}
```

### 3. Mid-term Memory (MTM)
#### a. Temporal Graph (Neo4j)
- **Má»¥c Ä‘Ã­ch**: lÆ°u **dÃ²ng thá»i gian** commit, checkpoints, thay Ä‘á»•i code.  
- **Node types**: `Commit`, `Checkpoint`  
- **Edges**: `NEXT`, `AFFECTS`  

**Output Example**:
```json
{
  "temporal_graph": [
    {"commit": "abc123", "time": "2025-09-30T10:00", "affects": ["checkpoints.rs"]}
  ]
}
```

#### b. Knowledge Graph (Neo4j)
- **Má»¥c Ä‘Ã­ch**: lÆ°u **quan há»‡ ngá»¯ nghÄ©a** giá»¯a function, class, module.  
- **Node types**: `Function`, `Class`, `Module`, `Concept`  
- **Edges**: `CALLS`, `BELONGS_TO`, `RELATED_TO`  

**Output Example**:
```json
{
  "knowledge_graph": [
    {"function": "apply_patch", "calls": ["validate_status"], "module": "git.rs"}
  ]
}
```

---

### 4. Long-term Memory (LTM)
#### a. Knowledge Graph (Neo4j)
- LÆ°u **kiáº¿n thá»©c bá»n vá»¯ng**: design docs, module relationship, domain knowledge.  
- **VÃ­ dá»¥ Output**:
```json
{
  "ltm_knowledge_graph": "Design doc v0.3 relations between AST and Parser"
}
```

#### b. Vector DB (Semantic Search)
- LÆ°u **embedding vectors** cá»§a docs, commit logs, spec.  
- Cho phÃ©p semantic retrieval theo cosine similarity / ANN.  

**Output Example**:
```json
{
  "ltm_vecdb": [
    {"chunk": "Bug report: drop(status) not defined", "score": 0.92}
  ]
}
```

---

### 5. Memory Aggregator
- **Input**: STM, MTM, LTM contexts.
- **Nhiá»‡m vá»¥**: Merge + deduplicate + ranking theo relevance score.
- **Output**: unified context (multi-layer).
```json
{
  "aggregated_context": "...merged stm+mtm+ltm..."
}
```

### 6. Context Compressor
- **Input**: Aggregated context.
- **Nhiá»‡m vá»¥**: NÃ©n Ä‘á»ƒ fit LLM (token budgeting).  
- **Output**: compressed context (500â€“2k tokens).

### 7. Reasoner / LLM
- **Input**: user query + compressed context.  
- **Output**: raw answer.

### 8. Response Synthesizer
- **Input**: LLM output.  
- **Output**: final formatted answer.

---

## ğŸ—ï¸ Build Neo4j Server

Báº¡n Ä‘Ã£ cÃ³ runner host, cÃ¡c bÆ°á»›c chuáº©n Ä‘á»ƒ cháº¡y Neo4j:

```bash
# 1. Pull Neo4j image
docker pull neo4j:5.25

# 2. Run Neo4j container
docker run \
  --name neo4j-lab \
  -p 7474:7474 -p 7687:7687 \
  -d \
  -e NEO4J_AUTH=neo4j/test123 \
  -v $HOME/neo4j/data:/data \
  neo4j:5.25

# 3. Truy cáº­p UI
http://localhost:7474

# 4. Query vÃ­ dá»¥
MATCH (c:Commit)-[:AFFECTS]->(f:File {name:"checkpoints.rs"})
RETURN c LIMIT 10;
```

Báº¡n cÃ³ thá»ƒ cháº¡y **2 database trong 1 instance Neo4j**:  
- `temporal_kg` â†’ cho commit timeline (MTM)  
- `longterm_kg` â†’ cho knowledge graph (LTM)  

ThÃªm má»™t **Vector DB** (Weaviate, Qdrant, Milvus, hoáº·c SQLite FAISS) Ä‘á»ƒ giá»¯ semantic search.

---

## ğŸ“‚ Cáº¥u trÃºc file Lab

```
memory_layer_lab/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ preprocessor.py
â”œâ”€â”€ stm.py
â”œâ”€â”€ mtm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ temporal_graph.py
â”‚   â”œâ”€â”€ knowledge_graph.py
â”‚   â””â”€â”€ query.py
â”œâ”€â”€ ltm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ knowledge_graph.py
â”‚   â”œâ”€â”€ vecdb.py
â”‚   â””â”€â”€ query.py
â”œâ”€â”€ aggregator.py
â”œâ”€â”€ compressor.py
â”œâ”€â”€ reasoner.py
â””â”€â”€ synthesizer.py
```

---

## ğŸ Input / Output chuáº©n cá»§a Lab

- **Input Lab**:  
  - User Query (string)  
  - Fake Embedding Vector (random float[], dim=128/384/512)  
  - Context Logs (JSON)

- **Output Lab**:  
  - Aggregated context (JSON)  
  - Compressed context (JSON/tokens)  
  - Final Reasoned Answer (string/JSON)
